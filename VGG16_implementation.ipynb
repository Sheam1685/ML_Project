{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, Flatten, Dropout,BatchNormalization ,Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator( rescale = 1./255,\n",
    "                                    validation_split=0.2,\n",
    "                                    rotation_range = 30,\n",
    "                                    width_shift_range = 0.2,\n",
    "                                    height_shift_range = 0.2,\n",
    "                                    shear_range = 0.2,\n",
    "                                    zoom_range = 0.2,\n",
    "                                    horizontal_flip = True,\n",
    "                                    vertical_flip=True,\n",
    "                                    fill_mode = 'nearest'\n",
    "                                  )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255, validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n",
      "Found 5741 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory('data/train',\n",
    "                                                target_size = (48,48),\n",
    "                                                class_mode = 'categorical',\n",
    "                                                batch_size = 64,\n",
    "                                                subset='training'\n",
    "                                              )\n",
    "\n",
    "val_data = val_datagen.flow_from_directory('data/train',\n",
    "                                            target_size = (48,48),\n",
    "                                            class_mode = 'categorical',\n",
    "                                            batch_size = 64,\n",
    "                                            subset='validation'\n",
    "                                          )\n",
    "\n",
    "test_data = test_datagen.flow_from_directory('data/test',\n",
    "                                              target_size = (48,48),\n",
    "                                              class_mode = 'categorical',\n",
    "                                              batch_size = 64\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = train_data.n//train_data.batch_size\n",
    "val_steps = val_data.n//val_data.batch_size\n",
    "test_steps = test_data.n//test_data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512)               2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15113543 (57.65 MB)\n",
      "Trainable params: 397319 (1.52 MB)\n",
      "Non-trainable params: 14716224 (56.14 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG16 model\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(48, 48, 3))\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))  # Assuming 7 classes for emotions\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.9799 - accuracy: 0.2487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samia\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 314s 875ms/step - loss: 1.9799 - accuracy: 0.2487 - val_loss: 1.6966 - val_accuracy: 0.3183 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "358/358 [==============================] - 307s 858ms/step - loss: 1.7684 - accuracy: 0.2840 - val_loss: 1.6876 - val_accuracy: 0.3281 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "358/358 [==============================] - 312s 871ms/step - loss: 1.7219 - accuracy: 0.3067 - val_loss: 1.6548 - val_accuracy: 0.3406 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "358/358 [==============================] - 304s 849ms/step - loss: 1.7048 - accuracy: 0.3101 - val_loss: 1.6566 - val_accuracy: 0.3425 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "358/358 [==============================] - 303s 847ms/step - loss: 1.7015 - accuracy: 0.3178 - val_loss: 1.6485 - val_accuracy: 0.3439 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "358/358 [==============================] - 308s 860ms/step - loss: 1.6847 - accuracy: 0.3241 - val_loss: 1.6651 - val_accuracy: 0.3478 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "358/358 [==============================] - 307s 858ms/step - loss: 1.6847 - accuracy: 0.3213 - val_loss: 1.6426 - val_accuracy: 0.3536 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "358/358 [==============================] - 308s 861ms/step - loss: 1.6823 - accuracy: 0.3247 - val_loss: 1.6288 - val_accuracy: 0.3588 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "358/358 [==============================] - 307s 857ms/step - loss: 1.6784 - accuracy: 0.3275 - val_loss: 1.6412 - val_accuracy: 0.3499 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "358/358 [==============================] - 309s 864ms/step - loss: 1.6794 - accuracy: 0.3271 - val_loss: 1.6380 - val_accuracy: 0.3455 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "358/358 [==============================] - 310s 865ms/step - loss: 1.6756 - accuracy: 0.3268 - val_loss: 1.6239 - val_accuracy: 0.3545 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "358/358 [==============================] - 303s 848ms/step - loss: 1.6716 - accuracy: 0.3288 - val_loss: 1.6146 - val_accuracy: 0.3622 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "358/358 [==============================] - 297s 829ms/step - loss: 1.6683 - accuracy: 0.3339 - val_loss: 1.6474 - val_accuracy: 0.3457 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "358/358 [==============================] - 297s 830ms/step - loss: 1.6679 - accuracy: 0.3323 - val_loss: 1.6223 - val_accuracy: 0.3613 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "358/358 [==============================] - 300s 837ms/step - loss: 1.6682 - accuracy: 0.3351 - val_loss: 1.6195 - val_accuracy: 0.3532 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "358/358 [==============================] - 298s 834ms/step - loss: 1.6683 - accuracy: 0.3335 - val_loss: 1.6345 - val_accuracy: 0.3559 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "358/358 [==============================] - 295s 824ms/step - loss: 1.6628 - accuracy: 0.3353 - val_loss: 1.6169 - val_accuracy: 0.3673 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "358/358 [==============================] - 307s 858ms/step - loss: 1.6577 - accuracy: 0.3401 - val_loss: 1.6099 - val_accuracy: 0.3659 - lr: 2.0000e-04\n",
      "Epoch 19/50\n",
      "358/358 [==============================] - 304s 849ms/step - loss: 1.6557 - accuracy: 0.3381 - val_loss: 1.6060 - val_accuracy: 0.3667 - lr: 2.0000e-04\n",
      "Epoch 20/50\n",
      "358/358 [==============================] - 303s 847ms/step - loss: 1.6503 - accuracy: 0.3429 - val_loss: 1.6033 - val_accuracy: 0.3664 - lr: 2.0000e-04\n",
      "Epoch 21/50\n",
      "358/358 [==============================] - 304s 850ms/step - loss: 1.6462 - accuracy: 0.3427 - val_loss: 1.6023 - val_accuracy: 0.3675 - lr: 2.0000e-04\n",
      "Epoch 22/50\n",
      "358/358 [==============================] - 304s 849ms/step - loss: 1.6468 - accuracy: 0.3434 - val_loss: 1.6000 - val_accuracy: 0.3648 - lr: 2.0000e-04\n",
      "Epoch 23/50\n",
      "358/358 [==============================] - 306s 856ms/step - loss: 1.6443 - accuracy: 0.3474 - val_loss: 1.6019 - val_accuracy: 0.3666 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "358/358 [==============================] - 307s 857ms/step - loss: 1.6421 - accuracy: 0.3484 - val_loss: 1.6029 - val_accuracy: 0.3655 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "358/358 [==============================] - 304s 849ms/step - loss: 1.6454 - accuracy: 0.3478 - val_loss: 1.6000 - val_accuracy: 0.3704 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "358/358 [==============================] - 303s 846ms/step - loss: 1.6423 - accuracy: 0.3483 - val_loss: 1.6016 - val_accuracy: 0.3657 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "358/358 [==============================] - 304s 849ms/step - loss: 1.6385 - accuracy: 0.3491 - val_loss: 1.5982 - val_accuracy: 0.3666 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "358/358 [==============================] - 304s 849ms/step - loss: 1.6399 - accuracy: 0.3454 - val_loss: 1.6010 - val_accuracy: 0.3657 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "358/358 [==============================] - 304s 848ms/step - loss: 1.6404 - accuracy: 0.3471 - val_loss: 1.6011 - val_accuracy: 0.3676 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "358/358 [==============================] - 302s 842ms/step - loss: 1.6403 - accuracy: 0.3491 - val_loss: 1.5994 - val_accuracy: 0.3718 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "358/358 [==============================] - 302s 844ms/step - loss: 1.6369 - accuracy: 0.3490 - val_loss: 1.6039 - val_accuracy: 0.3666 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "358/358 [==============================] - 302s 844ms/step - loss: 1.6337 - accuracy: 0.3526 - val_loss: 1.5973 - val_accuracy: 0.3689 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "358/358 [==============================] - 304s 851ms/step - loss: 1.6389 - accuracy: 0.3522 - val_loss: 1.5948 - val_accuracy: 0.3711 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "358/358 [==============================] - 302s 844ms/step - loss: 1.6355 - accuracy: 0.3488 - val_loss: 1.6032 - val_accuracy: 0.3643 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "358/358 [==============================] - 305s 853ms/step - loss: 1.6328 - accuracy: 0.3501 - val_loss: 1.5964 - val_accuracy: 0.3703 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "358/358 [==============================] - 304s 848ms/step - loss: 1.6390 - accuracy: 0.3497 - val_loss: 1.5952 - val_accuracy: 0.3736 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "358/358 [==============================] - 302s 844ms/step - loss: 1.6373 - accuracy: 0.3518 - val_loss: 1.5960 - val_accuracy: 0.3732 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "358/358 [==============================] - 303s 845ms/step - loss: 1.6328 - accuracy: 0.3554 - val_loss: 1.5979 - val_accuracy: 0.3701 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "358/358 [==============================] - 304s 850ms/step - loss: 1.6313 - accuracy: 0.3526 - val_loss: 1.5906 - val_accuracy: 0.3722 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "358/358 [==============================] - 302s 845ms/step - loss: 1.6356 - accuracy: 0.3510 - val_loss: 1.5928 - val_accuracy: 0.3708 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "358/358 [==============================] - 303s 845ms/step - loss: 1.6315 - accuracy: 0.3564 - val_loss: 1.5907 - val_accuracy: 0.3722 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "358/358 [==============================] - 303s 846ms/step - loss: 1.6302 - accuracy: 0.3502 - val_loss: 1.5925 - val_accuracy: 0.3736 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "358/358 [==============================] - 302s 844ms/step - loss: 1.6321 - accuracy: 0.3512 - val_loss: 1.5888 - val_accuracy: 0.3731 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "358/358 [==============================] - 303s 846ms/step - loss: 1.6305 - accuracy: 0.3540 - val_loss: 1.5925 - val_accuracy: 0.3745 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "358/358 [==============================] - 306s 854ms/step - loss: 1.6243 - accuracy: 0.3562 - val_loss: 1.5886 - val_accuracy: 0.3748 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "358/358 [==============================] - 304s 851ms/step - loss: 1.6308 - accuracy: 0.3543 - val_loss: 1.5897 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "358/358 [==============================] - 306s 854ms/step - loss: 1.6324 - accuracy: 0.3490 - val_loss: 1.5912 - val_accuracy: 0.3768 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "358/358 [==============================] - 306s 856ms/step - loss: 1.6272 - accuracy: 0.3554 - val_loss: 1.5935 - val_accuracy: 0.3743 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "358/358 [==============================] - 305s 851ms/step - loss: 1.6308 - accuracy: 0.3494 - val_loss: 1.5896 - val_accuracy: 0.3761 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "358/358 [==============================] - 309s 863ms/step - loss: 1.6314 - accuracy: 0.3537 - val_loss: 1.5884 - val_accuracy: 0.3794 - lr: 1.0000e-04\n",
      "112/112 [==============================] - 74s 665ms/step - loss: 1.5736 - accuracy: 0.3810\n",
      "Test Loss: 1.5736, Test Accuracy: 0.3810\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "checkpoint = ModelCheckpoint('emotion_model.h5', save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(train_data,\n",
    "                    steps_per_epoch=train_steps,\n",
    "                    epochs=50,\n",
    "                    validation_data=val_data,\n",
    "                    validation_steps=val_steps,\n",
    "                    callbacks=[reduce_lr, checkpoint, early_stop]\n",
    "                   )\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_data, steps=test_steps)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
